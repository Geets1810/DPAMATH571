---
title: "STOCK ANALYSIS"
author: "Tina"
date: "4/16/2018"
output: html_document
---
Read in data and data pre-processing
```{r}
rm(list=ls())
getwd()
setwd("/Users/tinapraveen/Desktop/StockAnalysis")
library(xlsx)
library(readxl)
file <- "/Users/tinapraveen/Desktop/StockAnalysis/JPM.xlsx"
jpm <- read_excel(file)
str(jpm)
row.has.na <- apply(jpm, 1, function(x){any(is.na(x))})
sum(row.has.na)
jpm.filtered <- jpm[!row.has.na, ]
summary(jpm.filtered)
jpm.filtered <- jpm.filtered[ , -c(1:3 , 16)]
str(jpm.filtered)
#jpm.filtered$CASH.DIVIDEND.PAYOUT.RATIO <-   #as.numeric(jpm.filtered$CASH.DIVIDEND.PAYOUT.RATIO)
#class(jpm.filtered$CASH.DIVIDEND.PAYOUT.RATIO)

```

DENSITY PLOTS(CHANGE)
#TODO density plot
```{r}


str(jpm.filtered[ ,1])
par(mfrow=c(3, 3))
d <- hist(jpm.filtered[ ,1])
 plot(d, type="n", main=colnames[1])
    polygon(d, col="red", border="gray")

for (i in 1:29) {
    d <- density(jpm.filtered[ ,i])
    plot(d, type="n", main=colnames[i])
    polygon(d, col="red", border="gray")
}

class(jpm.filtered$`CASH DIVIDEND PAYOUT RATIO`)
```
CORRELATION PLOTS
```{r}
library(psych)
library(corrplot)
pairs.panels(jpm.filtered[  ,2:10])
pairs.panels(jpm.filtered[  ,11:19])
pairs.panels(jpm.filtered[  ,20:29])
corrplot(cor(jpm.filtered),type="upper", method = "number")

```
LINEAR MODEL
```{r}
library(caret)
set.seed(1312)
# Normalize data 
jpm.filtered <- scale(jpm.filtered)
jpm.filtered <- data.frame(jpm.filtered)
sample(jpm.filtered)
index <- createDataPartition(jpm.filtered$CLOSE,p=0.8,list= FALSE)
jpm_train <- jpm.filtered[index, ]
jpm_test <- jpm.filtered[-index, ]
lmodel<- step(lm(CLOSE ~ .,data=jpm_train),direction = "both")
rmse_train <- sqrt(mean((jpm_train$CLOSE - predict(lmodel,jpm_train))^2))
rmse_test <- sqrt(mean((jpm_test$CLOSE - predict(lmodel,jpm_test))^2))
anova(lmodel)
summary(lmodel)


```
10- FOLD CROSS VALIDATION(implemented without using package)

```{r}
 jpm.filtered<-jpm.filtered[sample(nrow(jpm.filtered)),]

#Create 10 equally size folds
folds <- cut(seq(1,nrow(jpm.filtered)),breaks=10,labels=FALSE)
df_CV <-NULL
#Perform 10 fold cross validation
for(i in 1:10){
  print("Iteration:" )
  print(i)
  #Segment data by fold using the which() function 
  testIndexes <- which(folds==i,arr.ind=TRUE)
  testData <- jpm.filtered[testIndexes, ]
  trainData <- jpm.filtered[-testIndexes, ]
  lmodel2<- step(lm(CLOSE~ .,data=trainData),direction = "both")
  rmse_train <- sqrt(mean((trainData$CLOSE - predict(lmodel2,trainData))^2))
  print("Adjusted R -Sq:")
  print(summary(lmodel2)$r.squared)
  print("RMSE_train:")
  print(rmse_train)
  rmse_test <- sqrt(mean((testData$CLOSE - predict(lmodel2,testData))^2))
  print("RMSE_test for iteration ")
  print( rmse_test)
  print("---------------------------------------------------") 
  df_CV  <-cbind( c (rmse_train,rmse_test,summary(lmodel2)$adj.r.squared))
}
```
Gradient Boosting Method (GBM ):
```{r}
library(MASS)
library(iterators)
library(parallel)
library(doMC)
library(Metrics)
registerDoMC(16)
# caret model training parameters
controlParameters <- trainControl(method = "repeatedcv", number = 10, repeats = 5, 
                                 verboseIter = FALSE, allowParallel = TRUE)
gbmFit <- train(CLOSE ~ ., method = "gbm", metric = "RMSE", maximize = FALSE,trControl = controlParameters, tuneGrid = expand.grid(n.trees = (4:10) * 50, interaction.depth = c(5), shrinkage = c(0.05), n.minobsinnode = c(10)), data = jpm_train, verbose = FALSE)
rmse(jpm_train$CLOSE, predict(gbmFit, newdata = jpm_train))

# Predictions
preds1 <- predict(gbmFit, newdata = jpm_test)
rmse(jpm_test$CLOSE, preds1)

# 0.027
```
PRINCIPAL COMPONENT ANALYSIS(PCA)
```{r}
pca <- prcomp(jpm.filtered)
names(pca)
pca$sdev
pca$rotation <- -pca$rotation
pca$rotation
pca$x <- -pca$x
head(pca$x)
biplot(pca, scale=0)
raw <- pca$x[,1:2]
plot(raw[,1], raw[,2], col=rainbow(nrow(raw)), pch=20)




```